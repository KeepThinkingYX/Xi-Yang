<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>pub</title></head>
<body><h1><a name="directing-dnns-attention-for-facial-attribution-classification-usinggradient-weighted-class-activation-mapping" class="md-header-anchor"></a><span>Directing DNNs Attention for Facial Attribution Classification usingGradient-weighted Class Activation Mapping</span></h1>
<p><span>Xi Yang, The University of Tokyo</span></p>
<p><span>Bojian Wu, SIAT</span></p>
<p><span>Issei Sato, The University of Tokyo</span></p>
<p><span>Takeo Igarashi, The University of Tokyo</span></p>
<h2><a name="abstract" class="md-header-anchor"></a><span>Abstract</span></h2>
<p><span>Deep neural networks (DNNs) have a high accuracy on image classification tasks. However, DNNs trained by such dataset with co-occurrence bias may rely on wrong features while making decisions for classification. It will greatly affect the transferability of pre-trained DNNs.  In this paper,we propose an interactive method to direct classifiers paying attentions to the regions that are manually specified bythe users, in order to mitigate the influence of co-occurrence bias.  We test on CelebA dataset, the pre-trained AlexNet is fine-tuned to focus on the specific facial attributes based on the results of Grad-CAM.</span></p>
<p><img src='image.png' alt='' referrerPolicy='no-referrer' /></p>
<p><span>Examples from the CelebA dataset.  Grad-CAM shows that  a  pre-trained  DNN  ‘lipstick’  attribute  focuses  on  not  only the  mouth  region  but  also  on  the  eyes,  eyebrows,  and  other  regions (first row).  Our fine-tuned DNN focuses on the mouth only(second row). The predictive importance of various facial regions(high to low) is colorized blue to red.</span></p>
<h2><a name="download:" class="md-header-anchor"></a><span>Download:</span></h2>
<p><a href='https://arxiv.org/pdf/1905.00593.pdf' title=' '><span>PDF</span></a></p>
<p><a href='cvpr19_poster.pdf' title=' '><span>Poster</span></a></p>
<h2><a name="acknowledgement" class="md-header-anchor"></a><span>Acknowledgement</span></h2>
<p><span>This work was supported by JST CREST Grant Number JPMJCR17A1, Japan.</span></p>
<h2><a name="bibtex" class="md-header-anchor"></a><span>Bibtex</span></h2>
<p><span>@InProceedings{Yang_2019_CVPR_Workshops,</span>
<span>author = {Yang, Xi and Wu, Bojian and Sato, Issei and Igarashi, Takeo},</span>
<span>title = {Directing DNNs Attention for Facial Attribution Classification using Gradient-weighted Class Activation Mapping},</span>
<span>booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},</span>
<span>month = {June},</span>
<span>year = {2019}</span>
<span>}</span></p>
<p>&nbsp;</p>
</body>
</html>